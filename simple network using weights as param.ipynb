{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import keras\n",
    "from keras.models import load_model\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helpers vars for the notebook\n",
    "already_trained = False\n",
    "train_test_model = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following code is just copied over from the baseline_cnn_notebook\n",
    "# (with some modification)\n",
    "\n",
    "class ModelParameters:\n",
    "\n",
    "    def __init__(self,\n",
    "                 training_data_path,\n",
    "                 num_classes=28,\n",
    "                 num_epochs=5,\n",
    "                 batch_size=16,\n",
    "                 image_rows=1708,\n",
    "                 image_cols=1708,\n",
    "                 row_scale_factor=4,\n",
    "                 col_scale_factor=4,\n",
    "                 n_channels=3,\n",
    "                 shuffle=False):\n",
    "        \n",
    "        self.training_data_path = training_data_path\n",
    "        self.num_classes = num_classes\n",
    "        # what does n_epochs mean? it seems we pass this into the \"epochs\"\n",
    "        # parameter on the \"fit_generator\" method on our keras model\n",
    "        self.num_epochs = num_epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.row_dimension = np.int(image_rows / row_scale_factor)\n",
    "        self.col_dimension = np.int(image_cols / col_scale_factor)\n",
    "        self.n_channels = n_channels\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "\n",
    "class ImagePreprocessor:\n",
    "\n",
    "    def __init__(self, modelParameters):\n",
    "        self.image_path = modelParameters.training_data_path\n",
    "        self.n_channels = modelParameters.n_channels\n",
    "        self.row_dimension = modelParameters.row_dimension\n",
    "        self.col_dimension = modelParameters.col_dimension\n",
    "\n",
    "    def preprocess(self, image):\n",
    "        image = cv2.resize(image, (self.row_dimension, self.col_dimension))\n",
    "        image = np.true_divide(image, 255)\n",
    "        return image\n",
    "\n",
    "    def load_image(self, image_id):\n",
    "        return cv2.imread(self.image_path + image_id + '.jpg')\n",
    "\n",
    "class ImageBatchGenerator(keras.utils.Sequence):\n",
    "    \n",
    "    def __init__(self, image_ids, dataframe, model_params, image_processor):\n",
    "        '''\n",
    "        Writing a child implementation of keras.utils.Sequence will help us\n",
    "        manage our batches of data.\n",
    "        Each sequence must implement __len__ and __getitem__\n",
    "        This structure guarantees that the network will only train once on each\n",
    "        sample per epoch which is not the case with generators.\n",
    "        \n",
    "        We can use this class to instantiate training and validation generators\n",
    "        that we can pass into our keras model like:\n",
    "        \n",
    "        training_generator = ImageBatchLoader(...)\n",
    "        validation_generator = ImageBatchLoader(...)\n",
    "        model.set_generators(training_generator, validation_generator)\n",
    "        '''\n",
    "        self.image_ids = image_ids\n",
    "        self.dataframe = dataframe\n",
    "\n",
    "        # Helper classes\n",
    "        self._imageProcessor = image_processor\n",
    "\n",
    "        # Training parameters\n",
    "        self.batch_size = model_params.batch_size\n",
    "        self.dimensions = (model_params.row_dimension, model_params.col_dimension)\n",
    "        self.n_channels = model_params.n_channels\n",
    "        self.shuffle = model_params.shuffle\n",
    "\n",
    "        # Run on_epoch_end in _init_ to init our first image batch\n",
    "        self.on_epoch_end()\n",
    "        \n",
    "    def on_epoch_end(self):\n",
    "        '''\n",
    "        Tensorflow will run this method at the end of each epoch\n",
    "        So this is where we will modify our batch.\n",
    "        '''\n",
    "        self.indexes = np.arange(len(self.image_ids))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "            \n",
    "    def __len__(self):\n",
    "        # Denotes the number of batchs per epoch\n",
    "        return int(np.floor(len(self.image_ids) / self.batch_size))\n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        # Get this batches indexes\n",
    "        indexes = self.indexes[index * self.batch_size:(index+1) * self.batch_size]\n",
    "\n",
    "        # Get cooresponding image Ids\n",
    "        batch_image_ids = [self.image_ids[i] for i in indexes]\n",
    "\n",
    "        # Generate one batch of data\n",
    "        X, y = self.__generator(batch_image_ids)\n",
    "        \n",
    "        return X, y\n",
    "    \n",
    "    def __generator(self, batch_image_ids):\n",
    "\n",
    "        def get_target_class(imageid):\n",
    "            # .loc will lookup the row where the passed in statement is true\n",
    "            target = self.dataframe.loc[self.dataframe.imageId == imageid]\n",
    "            target = target.lesion.values[0]\n",
    "            return target\n",
    "\n",
    "        X = np.empty((self.batch_size, *self.dimensions, self.n_channels))\n",
    "        y = np.empty((self.batch_size), dtype=int)\n",
    "        z = np.empty((self.batch_size), dtype=int)\n",
    "        \n",
    "\n",
    "        for index, imageid in enumerate(batch_image_ids):\n",
    "            image = self._imageProcessor.load_image(imageid)\n",
    "            image = self._imageProcessor.preprocess(image)\n",
    "\n",
    "            X[index] = image\n",
    "            y[index] = get_target_class(imageid)\n",
    "            z[index] = get_target_class(imageid)\n",
    "\n",
    "        return X, { \"classificaton_output\": y, \"attention_map_output\": y }\n",
    "\n",
    "\n",
    "class PredictGenerator:\n",
    "\n",
    "    def __init__(self, image_ids, image_processor, image_path):\n",
    "        self.image_processor = image_processor\n",
    "        self.image_processor.image_path = image_path\n",
    "        self.image_ids = image_ids\n",
    "\n",
    "    def predict(self, model):\n",
    "        \n",
    "        y = np.empty(shape=(len(self.image_ids)))\n",
    "        \n",
    "        for n in range(len(self.image_ids)):\n",
    "            image = self.image_processor.load_image(self.image_ids[n])\n",
    "            image = self.image_processor.preprocess(image)\n",
    "            image = image.reshape((1, *image.shape))\n",
    "            y[n] = model.predict(image)\n",
    "        \n",
    "        return { \"classificaton_output\": y, \"attention_map_output\": y }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"./lesion-csv.csv\")\n",
    "train_df = pd.read_csv(\"./train.csv\")\n",
    "test_df = pd.read_csv(\"./test.csv\")\n",
    "\n",
    "# All we care about at this point is the id and class\n",
    "train_df = train_df.drop(\n",
    "    [\"Unnamed: 0\", \"Unnamed: 0.1\", \"teethNumbers\", \"description\", \"numberOfCanals\", \"date\", \"sequenceNumber\"], axis=1)\n",
    "\n",
    "test_df = test_df.drop(\n",
    "    [\"Unnamed: 0\", \"Unnamed: 0.1\", \"teethNumbers\", \"description\", \"numberOfCanals\", \"date\", \"sequenceNumber\"], axis=1)\n",
    "\n",
    "partition = {\n",
    "    \"train\": train_df.imageId.values,\n",
    "    \"validation\": test_df.imageId.values,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Conv2D, GlobalAveragePooling2D\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "class SimpleModel:\n",
    "    \n",
    "    def __init__(self, model_params):\n",
    "        self.img_rows = model_params.row_dimension\n",
    "        self.img_cols = model_params.col_dimension\n",
    "        self.n_channels = model_params.n_channels\n",
    "        self.input_shape = (self.img_rows, self.img_cols, self.n_channels)\n",
    "        self.num_epochs = model_params.num_epochs\n",
    "        self.metrics = ['accuracy']\n",
    "\n",
    "    @staticmethod\n",
    "    def build_classification_branch(inputs):\n",
    "        x = Conv2D(32, kernel_size=3, padding='same')(inputs)\n",
    "        x = Activation('relu')(x)\n",
    "        x = BatchNormalization(axis=-1)(x)\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "        x = Dropout(0.25)(x)\n",
    "        \n",
    "        x = Conv2D(64, kernel_size=3, padding='same')(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = BatchNormalization(axis=-1)(x)\n",
    "        x = Conv2D(64, kernel_size=3, padding='same')(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = BatchNormalization(axis=-1)(x)\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "        x = Dropout(0.25)(x)\n",
    "        \n",
    "        x = Conv2D(128, kernel_size=3, padding='same')(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = BatchNormalization(axis=-1)(x)\n",
    "        x = Conv2D(128, kernel_size=3, padding='same')(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = BatchNormalization(axis=-1)(x)\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "        x = Dropout(0.25)(x)\n",
    "        \n",
    "        x = Flatten()(x)\n",
    "        x = Dense(256)(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(0.5)(x)\n",
    "        x = Dense(1)(x)\n",
    "        x = Activation('sigmoid', name=\"classificaton_output\")(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    @staticmethod\n",
    "    def build_attention_map_branch(inputs):\n",
    "        x = Conv2D(16, kernel_size=3, padding='same')(inputs)\n",
    "        x = Activation('relu')(x)\n",
    "        x = BatchNormalization(axis=-1)(x)\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "        x = Dropout(0.25)(x)\n",
    "        \n",
    "        x = Conv2D(32, kernel_size=3, padding='same')(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = BatchNormalization(axis=-1)(x)\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "        x = Dropout(0.25)(x)\n",
    "        \n",
    "        x = Conv2D(32, kernel_size=3, padding='same')(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = BatchNormalization(axis=-1)(x)\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "        x = Dropout(0.25)(x)\n",
    "        \n",
    "        x = Flatten()(x)\n",
    "        x = Dense(128)(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(0.5)(x)\n",
    "        x = Dense(1)(x)\n",
    "        x = Activation('sigmoid', name=\"attention_map_output\")(x)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "    def build_multi_output(self):\n",
    "        input_shape = (self.img_rows, self.img_cols, self.n_channels)\n",
    "        \n",
    "        inputs = Input(shape=input_shape)\n",
    "        cl_branch = SimpleModel.build_classification_branch(inputs)\n",
    "        am_branch = SimpleModel.build_attention_map_branch(inputs)\n",
    "        \n",
    "        self.model = Model(\n",
    "            inputs=inputs,\n",
    "            outputs=[cl_branch, am_branch],\n",
    "            name='simple_model_test')\n",
    "        \n",
    "    def build_model(self):\n",
    "        input_1 = Input(shape=(224,224,3))\n",
    "        \n",
    "        conv_1 = Conv2D(64, kernel_size=3, activation='relu')\n",
    "        glap_1 = GlobalAveragePooling2D()\n",
    "        otpt_1 = Dense(1, activation=\"sigmoid\")\n",
    "        \n",
    "        conv_2 = Conv2D(32, kernel_size=3, activation='relu')\n",
    "        glap_2 = GlobalAveragePooling2D()\n",
    "        otpt_2 = Dense(1, activation=\"sigmoid\")\n",
    "        \n",
    "        \n",
    "        conv_1_otpt = conv_1(input_1)\n",
    "        glap_1_otpt = glap_1(conv_1_otpt)\n",
    "        otpt_1_otpt = otpt_1(glap_1_otpt)\n",
    "        \n",
    "        conv_2_otpt = conv_2(conv_1_otpt)\n",
    "        glap_2_otpt = glap_2(conv_2_otpt)\n",
    "        otpt_2_otpt = otpt_2(glap_2_otpt)\n",
    "        \n",
    "        \n",
    "        self.model = Model(inputs=input_1, outputs=[otpt_1.output])\n",
    "    \n",
    "    def compile_model(self):\n",
    "        sgd = SGD(lr=0.01, decay=1e-6, momentum=0.5, nesterov=True)\n",
    "        \n",
    "        losses = {\n",
    "            \"classificaton_output\": \"binary_crossentropy\", # TODO: change this to equation 5 fro mthe GAIN paper\n",
    "            \"attention_map_output\": \"binary_crossentropy\"\n",
    "        }\n",
    "        losses_weights = {\n",
    "            \"classificaton_output\": 1.0,\n",
    "            \"attention_map_output\": 1.0\n",
    "        }\n",
    "        \n",
    "        self.model.compile(\n",
    "            loss=losses, loss_weights=losses_weights, optimizer=sgd, metrics=self.metrics)\n",
    "    \n",
    "    def set_generators(self, train_generator, validation_generator):\n",
    "        self.training_generator = train_generator\n",
    "        self.validation_generator = validation_generator\n",
    "        \n",
    "    def learn(self):\n",
    "        return self.model.fit_generator(\n",
    "            generator=self.training_generator,\n",
    "            validation_data=self.validation_generator,\n",
    "            epochs=self.num_epochs,\n",
    "            use_multiprocessing=True,\n",
    "            workers=8,\n",
    "            verbose=1)\n",
    "\n",
    "    def score(self):\n",
    "        return self.model.evaluate_generator(\n",
    "            generator=self.validation_generator,\n",
    "            use_multiprocessing=True,\n",
    "            workers=8)\n",
    "\n",
    "    def predict(self, predict_generator):\n",
    "        y = predict_generator.predict(self.model)\n",
    "        return y\n",
    "\n",
    "    def save(self, modeloutputpath):\n",
    "        self.model.save(modeloutputpath)\n",
    "\n",
    "    def load(self, modelinputpath):\n",
    "        self.model = load_model(modelinputpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = './lesion_images/all_images_processed/'\n",
    "\n",
    "model_params = ModelParameters(\n",
    "    train_path,\n",
    "    num_epochs= 1 if train_test_model else 15,\n",
    "    batch_size=16,\n",
    "    image_rows=224,\n",
    "    image_cols=224,\n",
    "    row_scale_factor=1,\n",
    "    col_scale_factor=1)\n",
    "\n",
    "image_processor = ImagePreprocessor(model_params)\n",
    "\n",
    "training_generator = ImageBatchGenerator(partition['train'], data, model_params, image_processor)\n",
    "validation_generator = ImageBatchGenerator(partition['validation'], data, model_params, image_processor)\n",
    "predict_generator = PredictGenerator(partition['validation'], image_processor, train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 is incompatible with layer conv2d_10: expected ndim=4, found ndim=2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-b7658d4352bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msimple_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSimpleModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msimple_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_multi_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0msimple_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msimple_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_generators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-34-bcc033069e73>\u001b[0m in \u001b[0;36mbuild_multi_output\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0mcl_branch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSimpleModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_classification_branch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0mam_branch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSimpleModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_attention_map_branch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-34-bcc033069e73>\u001b[0m in \u001b[0;36mbuild_classification_branch\u001b[0;34m(inputs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mActivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchNormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_gpu/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    412\u001b[0m                 \u001b[0;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m                 \u001b[0;31m# with the input_spec specified in the layer constructor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m                 \u001b[0;31m# Collect input shapes to build layer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_gpu/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                                      \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m': expected ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                                      \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', found ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m                                      str(K.ndim(x)))\n\u001b[0m\u001b[1;32m    312\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_ndim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m                 \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 is incompatible with layer conv2d_10: expected ndim=4, found ndim=2"
     ]
    }
   ],
   "source": [
    "simple_model = SimpleModel(model_params)\n",
    "simple_model.build_multi_output()\n",
    "simple_model.compile_model()\n",
    "simple_model.set_generators(training_generator, validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "70/70 [==============================] - 8s 112ms/step - loss: 0.6962 - acc: 0.4964 - val_loss: 0.6948 - val_acc: 0.4875\n"
     ]
    }
   ],
   "source": [
    "history = simple_model.learn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
