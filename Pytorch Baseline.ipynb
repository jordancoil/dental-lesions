{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decided to use PyTorch. Keras was giving me quite a headache with it's abstractions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage import io\n",
    "import skimage.transform as sktrans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GeForce GTX 1070 Ti'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"./train.csv\")\n",
    "test_df = pd.read_csv(\"./test.csv\")\n",
    "\n",
    "# All we care about at this point is the id and class\n",
    "train_df = train_df.drop([\"Unnamed: 0\", \"Unnamed: 0.1\", \"teethNumbers\", \"description\", \"numberOfCanals\", \"date\", \"sequenceNumber\"], axis=1)\n",
    "test_df = test_df.drop([\"Unnamed: 0\", \"Unnamed: 0.1\", \"teethNumbers\", \"description\", \"numberOfCanals\", \"date\", \"sequenceNumber\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LesionDataset(Dataset):\n",
    "    \"\"\"Teeth Lesion dataset.\"\"\"\n",
    "    \n",
    "    def __init__(self, data_frame, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with image ids and labels.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        self.lesions_data_frame = data_frame\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.lesions_data_frame)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_id = self.lesions_data_frame.iloc[idx].imageId\n",
    "        image = io.imread(self.root_dir + image_id + '.jpg')\n",
    "        image = image.astype('float')\n",
    "        image = sktrans.resize(image, (224, 224))\n",
    "        \n",
    "        # swap color axis because\n",
    "        # numpy image: H x W x C\n",
    "        # torch image: C X H X W\n",
    "        image = image.transpose((2, 0, 1))\n",
    "        \n",
    "        label = self.lesions_data_frame.iloc[idx].lesion\n",
    "        label = label.astype('float')\n",
    "    \n",
    "        return torch.from_numpy(image), torch.from_numpy(np.array(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = LesionDataset(\n",
    "    train_df, \"./lesion_images/all_images_processed/\")\n",
    "valid_dataset = LesionDataset(\n",
    "    test_df, \"./lesion_images/all_images_processed/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 224, 224]) torch.Size([])\n",
      "torch.float64 torch.float64\n"
     ]
    }
   ],
   "source": [
    "image, label = train_dataset[0]\n",
    "print(image.size(), label.size())\n",
    "print(image.dtype, label.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    train_dataset, batch_size=4, shuffle=True, num_workers=4)\n",
    "valid_dataloader = DataLoader(\n",
    "    valid_dataset, batch_size=4, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 224, 224]) torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "for i_batch, batch in enumerate(train_dataloader):\n",
    "    images, labels = batch\n",
    "    print(images.size(), labels.size())\n",
    "\n",
    "    if i_batch == 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_classes):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, 16, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 5)\n",
    "        self.fc1 = nn.Linear(32 * 53 * 53, 256)\n",
    "        self.fc2 = nn.Linear(256, 84)\n",
    "        self.fc3 = nn.Linear(84, num_classes)\n",
    "        self.out = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # add sequence of convolutional and max pooling layers\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 32 * 53 * 53)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.out(self.fc3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(3, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=89888, out_features=256, bias=True)\n",
       "  (fc2): Linear(in_features=256, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=2, bias=True)\n",
       "  (out): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = [0,1]\n",
    "model = Net(len(classes))\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "# Optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.003, momentum= 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2,     1] loss: 0.053\n",
      "[2,    21] loss: 0.813\n",
      "[2,    41] loss: 0.663\n",
      "[2,    61] loss: 0.938\n",
      "[2,    81] loss: 0.713\n",
      "[2,   101] loss: 0.726\n",
      "[2,   121] loss: 0.876\n",
      "[2,   141] loss: 0.813\n",
      "[2,   161] loss: 0.813\n",
      "[2,   181] loss: 0.763\n",
      "[2,   201] loss: 0.788\n",
      "[2,   221] loss: 0.738\n",
      "[2,   241] loss: 0.738\n",
      "[2,   261] loss: 0.751\n",
      "[2,   281] loss: 0.926\n",
      "[2,     1] loss: 0.122\n",
      "[2,    21] loss: 0.851\n",
      "[2,    41] loss: 0.738\n",
      "[2,    61] loss: 0.876\n",
      "[2,    81] loss: 0.826\n",
      "Epoch: 1 \tTraining Loss: 0.790293 \tValidation Loss: 0.819286\n",
      "Validation loss decreased (inf --> 0.819286).  Saving model ...\n",
      "[3,     1] loss: 0.041\n",
      "[3,    21] loss: 0.713\n",
      "[3,    41] loss: 0.801\n",
      "[3,    61] loss: 0.801\n",
      "[3,    81] loss: 0.776\n",
      "[3,   101] loss: 0.801\n",
      "[3,   121] loss: 0.776\n",
      "[3,   141] loss: 0.788\n",
      "[3,   161] loss: 0.801\n",
      "[3,   181] loss: 0.801\n",
      "[3,   201] loss: 0.738\n",
      "[3,   221] loss: 0.788\n",
      "[3,   241] loss: 0.801\n",
      "[3,   261] loss: 0.826\n",
      "[3,   281] loss: 0.863\n",
      "[3,     1] loss: 0.109\n",
      "[3,    21] loss: 0.776\n",
      "[3,    41] loss: 0.888\n",
      "[3,    61] loss: 0.788\n",
      "[3,    81] loss: 0.826\n",
      "Epoch: 2 \tTraining Loss: 0.790293 \tValidation Loss: 0.819286\n",
      "Validation loss decreased (0.819286 --> 0.819286).  Saving model ...\n",
      "[4,     1] loss: 0.053\n",
      "[4,    21] loss: 0.776\n",
      "[4,    41] loss: 0.838\n",
      "[4,    61] loss: 0.788\n",
      "[4,    81] loss: 0.801\n",
      "[4,   101] loss: 0.788\n",
      "[4,   121] loss: 0.851\n",
      "[4,   141] loss: 0.813\n",
      "[4,   161] loss: 0.851\n",
      "[4,   181] loss: 0.726\n",
      "[4,   201] loss: 0.738\n",
      "[4,   221] loss: 0.776\n",
      "[4,   241] loss: 0.726\n",
      "[4,   261] loss: 0.838\n",
      "[4,   281] loss: 0.738\n",
      "[4,     1] loss: 0.122\n",
      "[4,    21] loss: 0.826\n",
      "[4,    41] loss: 0.763\n",
      "[4,    61] loss: 0.901\n",
      "[4,    81] loss: 0.813\n",
      "Epoch: 3 \tTraining Loss: 0.790293 \tValidation Loss: 0.819286\n",
      "Validation loss decreased (0.819286 --> 0.819286).  Saving model ...\n",
      "[5,     1] loss: 0.053\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-0056bdfddbff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# train the model #\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m# move tensors to GPU if CUDA is available\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_gpu/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcvd_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_gpu/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    608\u001b[0m             \u001b[0;31m# need to call `.task_done()` because we don't use `.join()`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_gpu/lib/python3.6/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rlock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_gpu/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mrecv_bytes\u001b[0;34m(self, maxlength)\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"negative maxlength\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbuf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bad_message_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_gpu/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"!i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxsize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_gpu/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mremaining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m             \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# number of epochs to train the model\n",
    "n_epochs = 5 \n",
    "\n",
    "valid_loss_min = np.Inf # track change in validation loss\n",
    "\n",
    "for epoch in range(1, n_epochs+1):\n",
    "\n",
    "    # keep track of training and validation loss\n",
    "    train_loss = 0.0\n",
    "    valid_loss = 0.0\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    # train the model #\n",
    "    model.train()\n",
    "    for i_batch, batch in enumerate(train_dataloader):\n",
    "        data, target = batch\n",
    "        # move tensors to GPU if CUDA is available\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "        # clear the gradients of all optimized variables\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data.float())\n",
    "        # calculate the batch loss\n",
    "        loss = criterion(output, target.long())\n",
    "        # backward pass: compute gradient of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "        # perform a single optimization step (parameter update)\n",
    "        optimizer.step()\n",
    "        # update training loss\n",
    "        train_loss += loss.item()*data.size(0)\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        if i_batch % 20 == 0:\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i_batch + 1, running_loss / 20))\n",
    "            running_loss = 0.0\n",
    "        \n",
    "    # Validating the model\n",
    "    model.eval()\n",
    "    for i_batch, batch in enumerate(valid_dataloader):\n",
    "        data, target = batch\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data.float())\n",
    "        # calculate the batch loss\n",
    "        loss = criterion(output, target.long())\n",
    "        # update average validation loss \n",
    "        valid_loss += loss.item() * data.size(0)\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        if i_batch % 20 == 0:\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch, i_batch, running_loss / 20))\n",
    "            running_loss = 0.0\n",
    "    \n",
    "    # calculate average losses\n",
    "    train_loss = train_loss/len(train_dataloader.dataset)\n",
    "    valid_loss = valid_loss/len(valid_dataloader.dataset)\n",
    "    \n",
    "\n",
    "        \n",
    "    # print training/validation statistics \n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "        epoch, train_loss, valid_loss))\n",
    "    \n",
    "    # save model if validation loss has decreased\n",
    "    if valid_loss <= valid_loss_min:\n",
    "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "        valid_loss_min,\n",
    "        valid_loss))\n",
    "        torch.save(model.state_dict(), 'pytorch_lesion_model.pt')\n",
    "        valid_loss_min = valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 49 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in valid_dataloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.cuda(), labels.cuda()\n",
    "        outputs = model(images.float())\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels.long()).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_loss = 0.0\n",
    "train_loss/len(train_dataloader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[nan, nan],\n",
       "        [nan, nan],\n",
       "        [nan, nan],\n",
       "        [nan, nan]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "class CNN_Model(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_classes):\n",
    "        super(CNN_Model, self).__init__()\n",
    "        \n",
    "        self.dataloader = dataloader\n",
    "        \n",
    "        self.densenet = models.densenet161(pretrained=True)\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 53 * 53, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, num_classes)\n",
    "        self.out_act = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        output = self.densenet(x)\n",
    "        \n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        \n",
    "        x1 = x.view(-1, 16 * 53 * 53)\n",
    "        x1 = F.relu(self.fc1(x1))\n",
    "        x1 = F.relu(self.fc2(x1))\n",
    "        x1 = self.out_act(self.fc3(x1))\n",
    "        \n",
    "        return x1\n",
    "\n",
    "    \n",
    "class CNN:\n",
    "    \n",
    "    def __init__(self, dataloader, model):\n",
    "        self.dataloader = dataloader\n",
    "        self.criterion = nn.BCELoss()\n",
    "        self.optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "        self.model = model\n",
    "        self.running_loss = 0.0\n",
    "        self.num_epochs = 2\n",
    "        \n",
    "        self.register_hooks(\"conv2\")\n",
    "        \n",
    "    def register_hooks(self, target_layer):\n",
    "        print(\"Registering Hooks\")\n",
    "        \n",
    "        def forward_hook(module, input_, output_):\n",
    "            self._last_activation = output_\n",
    "\n",
    "        def backward_hook(module, grad_in, grad_out):\n",
    "            self._last_grad = grad_out[0]\n",
    "\n",
    "        for layer_name, layer in self.model.named_modules():\n",
    "            if layer_name == target_layer:\n",
    "                layer.register_forward_hook(forward_hook)\n",
    "                layer.register_backward_hook(backward_hook)\n",
    "                print(\"Hooks Regsitered for layer: \", target_layer)\n",
    "                break\n",
    "    \n",
    "    def train(self):\n",
    "        print('Starting Training')\n",
    "        for epoch in range(self.num_epochs):  # loop over the dataset multiple times\n",
    "            for batch_idx, data in enumerate(self.dataloader, 0):\n",
    "                # get the inputs\n",
    "                inputs, labels = data\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "                classification, class_loss, attention_map = self.forward(inputs, labels)\n",
    "                \n",
    "                class_loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                # print statistics \n",
    "                if batch_idx % 20 == 0:    # print every 20 mini-batches\n",
    "                    print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                        epoch, batch_idx * len(data), len(dataloader.dataset),\n",
    "                        100. * batch_idx / len(dataloader), class_loss.item()))\n",
    "\n",
    "        print('Finished Training')\n",
    "    \n",
    "    def forward(self, inputs, labels):\n",
    "        # forward + backward + optimize\n",
    "        classification = self.model(inputs)\n",
    "        \n",
    "        float_labels = labels.float()\n",
    "        \n",
    "        # Need to do this so that self._last_grad will be set.\n",
    "        grad_target = (classification * float_labels).sum()\n",
    "        grad_target.backward(gradient=float_labels * classification, retain_graph=True)\n",
    "        \n",
    "        self.model.zero_grad()\n",
    "\n",
    "        # attention map stuff?\n",
    "        # Eq 1\n",
    "        class_weights = F.avg_pool2d(\n",
    "            self._last_grad, \n",
    "            (self._last_grad.shape[-2], self._last_grad.shape[-1]),\n",
    "            1)\n",
    "        class_weights_new_shape = (\n",
    "            class_weights.shape[0] * class_weights.shape[1], \n",
    "            class_weights.shape[2], class_weights.shape[3])\n",
    "        class_weights_reshaped = class_weights.view(class_weights_new_shape).unsqueeze(0)\n",
    "        \n",
    "\n",
    "        # Eq 2\n",
    "        weights = self._last_activation\n",
    "        weights_new_shape = (weights.shape[0] * weights.shape[1], weights.shape[2], weights.shape[3])\n",
    "        weights_reshaped = weights.view(weights_new_shape).unsqueeze(0)\n",
    "\n",
    "        grad_cam = F.relu(F.conv2d(weights_reshaped, class_weights_reshaped))\n",
    "        attention_map = F.upsample(grad_cam, size=inputs.size()[2:], mode='bilinear')\n",
    "        \n",
    "        class_loss = self.criterion(classification, float_labels)\n",
    "        \n",
    "        return classification, class_loss, attention_map\n",
    "    \n",
    "    def predict(self, validation_set):\n",
    "        testloader = DataLoader(validation_set, batch_size=4,\n",
    "                        shuffle=True, num_workers=4)\n",
    "\n",
    "        correct1 = 0\n",
    "#         correct2 = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for data in testloader:\n",
    "                images, labels = data\n",
    "                out1 = self.model(images)\n",
    "#                 out1, out2 = net(images)\n",
    "                _, predicted1 = torch.max(out1.data, 1)\n",
    "#                 _, predicted2 = torch.max(out2.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct1 += (predicted1 == labels).sum().item()\n",
    "#                 correct2 += (predicted2 == labels).sum().item()\n",
    "\n",
    "        print('Accuracy of the network on the test images: %d %%' % (100 * correct1 / total))\n",
    "#         print('Accuracy of the network on the test images: %d %%' % (100 * correct2 / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = CNN_Model(1)\n",
    "cnn = CNN(dataloader, cnn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.predict(validation_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attention map output test\n",
    "\n",
    "for i_batch, sample_batched in enumerate(dataloader):\n",
    "    images, labels = sample_batched\n",
    "    \n",
    "    classification, class_loss, attention_map = cnn.forward(images, labels)\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_heatmap = attention_map[0].detach().numpy().flatten()\n",
    "print(flat_heatmap.shape)\n",
    "np.max(flat_heatmap)\n",
    "# np.true_divide(flat_heatmap, np.max(flat_heatmap))\n",
    "# heatmap = attention_map[0].permute(1, 2, 0).detach().numpy()\n",
    "# flat_heatmap = heatmap.flatten()\n",
    "\n",
    "# heatmap = np.true_divide(heatmap, np.max(heatmap))\n",
    "# heatmap = cv2.applyColorMap(np.uint8(255*heatmap), cv2.COLORMAP_JET)\n",
    "# print(heatmap.shape)\n",
    "# plt.imshow(heatmap)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think what I need to do, is to create an initial classification model to load into the Attention Map class. From there I can define a new forward pass that will use the classification output of that model.\n",
    "\n",
    "I can also define the layer names in that model and use the register hooks function to apply a backward hook to the last conv layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, m in net.named_modules():\n",
    "    print(\"index: \", idx)\n",
    "    print(\"layer: \", m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
